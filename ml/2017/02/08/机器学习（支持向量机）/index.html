<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习（支持向量机） | Machine-Learning</title>
  <meta name="author" content="dylan">

  
  <meta name="description" content="A place of Machine-Learning">
  
  

  <link rel="alternate" href="/atom.xml" title="Machine-Learning" type="application/atom+xml">
  <link rel="stylesheet" href="/ml/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8/jquery.min.js"></script>
  
</head>

<body>
  <header id="header" class="inner"><nav>
  <ul>
    
      <li><a href="">Machine-Learning</a></li>
    
  </ul>
</nav></header>
  <div id="content" class="inner"><article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <header>
    
  
    <h1 class="title">机器学习（支持向量机）</h1>
  

    <time datetime="2017-02-08T12:00:00.000Z">
  <span class="day">8</span><span class="month">Feb</span>
</time>
  </header>
  <div class="entry-content">
    
      <h2 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h2><p>===</p>
<p>支持向量机（<em>Support Vector Machines, SVM</em>）。在介绍SVM之前，先解释几个概念：</p>
<ul>
<li>线性可分：假设一个平面中有若凡个圆形与三角形，可以使用一条直线将两组数据点分开，那么叫做线性可分。</li>
<li>分隔超平面：上面提到的将数据集分开的直线，称为分隔超平面。</li>
<li>超平面：在上面的例子中，是一个平面，那如果是一个三维的，那么用来分割点的就是一个平面，如果是N维的的？这个玩意就被叫做超平面，也就是分类的决策边界。</li>
<li>间隔：数据点到分隔面的距离被称为间隔。一般情况下，我们希望间隔尽可能的大，这是因为如果我们犯错或者在有限的数据集上训练分类器的话，我们希望分类器尽可能健壮。</li>
<li>支持向量：离分隔超平面最近的那些点。</li>
</ul>
<a id="more"></a>
<h4 id="寻找最大间隔"><a href="#寻找最大间隔" class="headerlink" title="寻找最大间隔"></a>寻找最大间隔</h4><p>如果求解数据集的最佳分隔直线？分隔超平面的形式可以写成：</p>
<p><img src="../imgs/ml-svm-1.png" alt=""></p>
<p>要计算点A到分隔超平面的距离，就必须给出点到分隔面的法线或垂线的长度，该值写为：</p>
<p><img src="../imgs/ml-svm-2.png" alt=""></p>
<blockquote>
<p><code>||w||</code>的意思是w向量的各个元素的平方和的开平方<br>这里的常数b类似于Logistic回归中的截距Wо。</p>
</blockquote>
<p>这里的向量w和常数b一起描述了所给数据的分隔线或超平面，接下来我们讨论分类器。</p>
<h6 id="分类器求解的优化问题"><a href="#分类器求解的优化问题" class="headerlink" title="分类器求解的优化问题"></a>分类器求解的优化问题</h6><p>前面已经提到了分类器，但还没有介绍它的工作原理。理解其工作原理将有助于理解基于优化问题的分类器求解过程。输入数据给分类器会输出一个类别标签，这相当于一个类似Sigmoid的函数在作用。下面将使用类似<code>海维塞德阶跃函数</code>的函数对分隔超平面的公式作用得到：</p>
<p><img src="../imgs/ml-svm-3.png" alt=""></p>
<p>其中，当u&lt;0时，f(u)输出-1，反之则输出+1。这和钱一张的Logistic回归有所不同，那里的类别标签是0或1。这里为什么呢？因为-1和+1仅差一个符号，便于数学上的处理。我们可以通过一个统一的公式来表示间隔或者数据点到分隔超平面的距离，同时不必担数据到底是属于-1还是+1类。</p>
<p>当计算数据点到分隔面的距离并确定分隔面的放置位置时，间隔通过：</p>
<p><img src="../imgs/ml-svm-4.png" alt=""></p>
<p>来计算，这时候就能提现出-1和+1的好处了，如果数据点处于正方向并且离分隔超平面很远的位置时：</p>
<p><img src="../imgs/ml-svm-1.png" alt=""></p>
<p>会是一个很大的正数，同时，上式也是一个很大的正数，而如果数据点处于负方向的-1类并且离分隔超平面很远的位置时，由于类别标签为-1，上式仍然是一个很大的正数。现在的目标就是找出分类器中的w和b。为此，我们必须找到具有最小间隔的数据点，而这些数据点也就是前面提到的支持向量。一旦找到具有最小间隔的数据点，我们就需要对该间隔最大化，这就可以写作：</p>
<p><img src="../imgs/ml-svm-5.JPG" alt=""></p>
<p>直接求解上述问题相当困难，所以我们将它转换为另一种更容易求解的形式。首先考察一下上式中大括号内的部分。由于对乘积进行优化是一件很讨厌的事情，因此我们要做的是固定其中一个因子而最大化其他因子。如果另所有支持向量的</p>
<p><img src="../imgs/ml-svm-7.png" alt=""></p>
<p>都等于1，只有那些离分隔超平面最近的点得到的值才为1。而离分隔超平面越远的数据点，值也就越大。</p>
<p>在上述优化问题中，给定了一些约束条件然后求最优值，因此该问题是一个带约束条件的优化问题。这里的约束条件就是：</p>
<p><img src="../imgs/ml-svm-6.png" alt=""></p>
<p>对于这类优化问题，有一个非常著名的求解方法，即<code>拉格朗日乘子法</code>，通过引入<code>拉格朗日乘子</code>，我们就可以基于约束条件来表述原来的问题。由于这里的约束条件都是基于数据点的，因此我们就可以将超平面写成数据点的形式。于是，优化目标的函数最后可以写成：</p>
<p><img src="../imgs/ml-svm-8.JPG" alt=""></p>
<blockquote>
<p>尖括号内标识两个向量的乘积</p>
</blockquote>
<p>其约束条件为：</p>
<p><img src="../imgs/ml-svm-9.png" alt=""></p>
<p>至此，一切都很完美，但是这里有个假设：数据必须100%线性可分。目前为止，我们知道几乎所有数据都不会这样，这时我们就可以通过引入<code>松弛变量</code>，来允许有些数据点可以处于分隔面的错误一侧。这样我们的优化目标就能保持仍然不变，但是此时新的约束条件则变为：</p>
<p><img src="../imgs/ml-svm-10.png" alt=""></p>
<p>这里的常数c用于控制”最大化间隔” 和 “保证大部分点的函数间隔小于1.0” 这两个目标的权重。在优化算法的实现代码中，常数C是一个参数，因此我们就可以通过调节该参数得到不同的结果。一旦求出了新的alpha，那么分隔超平面就可以通过这些alpha来表达。这一结论十分直接，SVM中的主要工作就是求解这些alpha。要理解刚才这些公式还需要大量的知识，如果你有兴趣，可以去搜索一下相关的推导过程。</p>
<h6 id="SVM应用中的一般框架"><a href="#SVM应用中的一般框架" class="headerlink" title="SVM应用中的一般框架"></a>SVM应用中的一般框架</h6><ul>
<li>收集数据：可以使用任意方法</li>
<li>准备数据：需要数值型数据</li>
<li>分析数据：有助于可视化分隔超平面</li>
<li>训练算法：SVM的大部分时间都源自训练，该过程主要实现两个参数的调优</li>
<li>测试算法：十分简单的计算过程就可以实现</li>
<li>使用算法：几乎所有的分类问题都可以使用SVM，值得一提的是，SVM本身是一个二类分类器，对多累问题应用SVM需要对代码做一些修改。</li>
</ul>
<h6 id="SMO-高效优化算法"><a href="#SMO-高效优化算法" class="headerlink" title="SMO 高效优化算法"></a>SMO 高效优化算法</h6><p>接下来我们优化2个上面提到的式子，一个是最小化的目标函数，一个是在优化过程中必须遵循的约束条件。下面我们先看<strong>Platt的SMO算法</strong>。SMO表示<code>序列最小优化</code>，将大优化问题分解为多个小优化问题求解，这些小优化问题往往很容易求解，并且对他们的顺序求解的结果与将他们作为整体来求解是完全一致的。在结果完全相同时，SMO算法的求解时间短很多。SMO算法的目标是求出一系列alpha和b，一旦求出了这些alpha，就很容易计算出权重向量w并得到分隔超平面。SMO算法的工作原理是：每次循环中选择两个alpha进行优化处理。一旦找到一对合适的alpha，那么就增大其中一个同时减小另一个。这里所谓的合适，就是指两个alpha必须要符合一定的条件，条件之一就是这两个alpha必须要在间隔边界之外，而其第二个条件则是这两个alpha还没有进行过区间化处理或者不在边界上。</p>
<p><strong>应用简化版 SMO 算法处理小规模数据集</strong>：完整算法的实现需要大量的代码，我们先对算法进行简化处理，以便了解算法的基本工作思路，之后再基于简化版给出完整版。简化版代码量虽少，但是执行速度慢。在SMO算法中，外循环确定要优化的最佳alpha对。而简化版会跳过这一部分，首先在数据集上遍历每一个alpha，然后在剩下的alpha集合中随机选择另一个alpha，从而构建alpha对。这里有一点相当重要，就是我们要同时改变两个alpha，之所以这样做是因为我们有一个约束条件：</p>
<p><img src="../imgs/ml-svm-11.png" alt=""></p>
<p>由于改变一个alpha可能会导致该约束条件失效，因此我们总是同时改变两个alpha。为此，我们将构建一个辅助函数，用于在某个区间范围内随机选择一个整数。同时，我们也需要另一个辅助函数，用于在数值太大时对其进行调整。我们开始写代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 打开文件进行逐行解析</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(filename)</span> :</span></div><div class="line">  dataMat = []</div><div class="line">  labelMat = []</div><div class="line"></div><div class="line">  fr = open(filename)</div><div class="line"></div><div class="line">  <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines() :</div><div class="line">    lineArr = line.strip().split(<span class="string">'\t'</span>)</div><div class="line">    dataMat.append([float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])</div><div class="line">    labelMat.append(float(lineArr[<span class="number">2</span>]))</div><div class="line"></div><div class="line">  <span class="keyword">return</span> dataMat, labelMat</div><div class="line"></div><div class="line"><span class="comment"># i：第一个alpha的下标</span></div><div class="line"><span class="comment"># m：所有alpha的数目</span></div><div class="line"><span class="comment"># 只要函数值不等于输入值i，函数就会随机进行选择</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJrand</span><span class="params">(i, m)</span> :</span></div><div class="line">  j = i</div><div class="line">  <span class="keyword">while</span> ( j == i ) :</div><div class="line">    j = int(random.uniform(<span class="number">0</span>, m))</div><div class="line">  <span class="keyword">return</span> j</div><div class="line"></div><div class="line"><span class="comment"># 用于调整大于H或小于L的alpha值</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">clipAlpha</span><span class="params">(aj, H, L)</span> :</span></div><div class="line">  <span class="keyword">if</span> aj &gt; H :</div><div class="line">    aj = H</div><div class="line">  <span class="keyword">if</span> L &gt; aj :</div><div class="line">    aj = L</div><div class="line">  <span class="keyword">return</span> aj</div></pre></td></tr></table></figure>
<p>进行简单的读取测试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> svmMLiA</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>dataArr, labelArr = svmMLiA.loadDataSet(<span class="string">'testSet.txt'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>labelArr</div><div class="line">[<span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span></div><div class="line">, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, -</div><div class="line"><span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>,</div><div class="line"> <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>, <span class="number">-1.0</span>]</div></pre></td></tr></table></figure>
<p>我们也可以看的出来，这里使用的类别标签是-1和1，并不是0和1.上述工作完成后，就可以使用SMO算法的第一个版本了，该SMO函数的伪代码大致如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">创建一个alpha向量并将其初始化为0向量</div><div class="line">当迭代次数小于最大迭代次数时 （外循环）</div><div class="line">  对数据集中的每个数据向量 （内循环）：</div><div class="line">    如果该数据向量可以被优化：</div><div class="line">      随机选择另外一个数据向量</div><div class="line">      同时优化这两个向量</div><div class="line">      如果两个向量都不能被优化，退出内循环</div><div class="line">  如果所有向量都被有被优化，增加迭代数目，继续下一次循环</div></pre></td></tr></table></figure>
<blockquote>
<p>在python中，如果某行以 <code>\</code> 符号结束，那么就意味着该行语句没有结束并会在下一行延续。 类似与 OC 中宏定义的 <code>\</code> 换行，接下来我们来看一个简化版的SMO算法：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># dataMatIn 数据集</span></div><div class="line"><span class="comment"># classLabels 类别标签</span></div><div class="line"><span class="comment"># C 常数C</span></div><div class="line"><span class="comment"># toler 容错率</span></div><div class="line"><span class="comment"># maxIter 最大循环次数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoSimple</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter)</span> :</span></div><div class="line">  <span class="comment"># 处理为矩阵</span></div><div class="line">  dataMatrix = mat(dataMatIn)</div><div class="line">  labelMat = mat(classLabels).transpose()</div><div class="line"></div><div class="line">  b = <span class="number">0</span></div><div class="line">  m, n = shape(dataMatrix)</div><div class="line"></div><div class="line">  alphas = mat(zeros((m, <span class="number">1</span>))) </div><div class="line">  iter = <span class="number">0</span> <span class="comment"># 遍历数据集的次数</span></div><div class="line"></div><div class="line">  <span class="keyword">while</span> ( iter &lt; maxIter ) :</div><div class="line">    alphaPairsChanged = <span class="number">0</span> <span class="comment"># 记录alpha是否已经进行优化</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m) :</div><div class="line">      fXi = float( multiply(alphas, labelMat).T * (dataMatrix*dataMatrix[i, :].T) ) + b</div><div class="line">      Ei = fXi - float(labelMat[i]) <span class="comment"># 计算误差，基于实例的预测结果和真实结果</span></div><div class="line">      <span class="comment"># 如果误差很大，可以对该数据实例所对应的alpha值进行优化，</span></div><div class="line">      <span class="keyword">if</span> (labelMat[i] * Ei &lt; -toler) <span class="keyword">and</span> (alphas[i] &lt; C) <span class="keyword">or</span> ((labelMat[i] * Ei &gt; toler) <span class="keyword">and</span> (alphas[i] &gt; <span class="number">0</span>)):</div><div class="line"></div><div class="line">        <span class="comment"># 优化，随机选择第二个alpha，保证alpha在0与C之间</span></div><div class="line"></div><div class="line">        <span class="comment"># 随机选择第二个alpha， 同样计算误差</span></div><div class="line">        j = selectJrand(i, m)</div><div class="line">        fXj = float(multiply(alphas, labelMat).T * (dataMatrix * dataMatrix[j, :].T)) + b</div><div class="line">        Ej = fXj - float(labelMat[j])</div><div class="line"></div><div class="line">        <span class="comment"># python方法传递的是引用，所以这里使用copy强制分配内存</span></div><div class="line">        alphaIold = alphas[i].copy()</div><div class="line">        alphaJold = alphas[j].copy()</div><div class="line"></div><div class="line">        <span class="comment"># 将 alpha[j] 调整到0与C之间</span></div><div class="line">        <span class="keyword">if</span> (labelMat[i] != labelMat[j]) :</div><div class="line">          L = max(<span class="number">0</span>, alphas[j] - alphas[i])</div><div class="line">          H = min(C, C + alphas[j] - alphas[i])</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">          L = max(<span class="number">0</span>, alphas[j] + alphas[i] - C)</div><div class="line">          H = min(C, alphas[j] + alphas[i])</div><div class="line"></div><div class="line">        <span class="comment"># 如果L和H相等，就不错任何改变</span></div><div class="line">        <span class="keyword">if</span> L == H: <span class="keyword">print</span> <span class="string">"L == H"</span>; <span class="keyword">continue</span></div><div class="line"></div><div class="line">        <span class="comment"># eta是alpha[j]的最优修改量，如果eta为0，就需要退出for循环当前迭代的过程</span></div><div class="line">        eta = <span class="number">2.0</span> * dataMatrix[i, :] * dataMatrix[j, :].T - dataMatrix[i, :] * dataMatrix[i, :].T - dataMatrix[j, :] * dataMatrix[j, :].T</div><div class="line">        <span class="keyword">if</span> eta &gt;= <span class="number">0</span>: <span class="keyword">print</span> <span class="string">"eta &gt;= 0"</span>; <span class="keyword">continue</span></div><div class="line"></div><div class="line">        <span class="comment"># </span></div><div class="line">        alphas[j] -= labelMat[j] * (Ei - Ej) / eta</div><div class="line">        alphas[j] = clipAlpha(alphas[j], H, L)</div><div class="line"></div><div class="line">        <span class="comment"># 检查 alpha[j] 是否有轻微的改变</span></div><div class="line">        <span class="keyword">if</span> (abs(alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>) : <span class="keyword">print</span> <span class="string">"j not moving enough"</span>; <span class="keyword">continue</span></div><div class="line"></div><div class="line">        <span class="comment"># 同时进行改变 alpha[i] 和 alpha[j]，改变的方向是相反的（一个增加，另外一个减少）</span></div><div class="line">        alphas[i] += labelMat[j] * labelMat[i] * (alphaJold - alphas[j])</div><div class="line"></div><div class="line">        <span class="comment"># 在优化之后，给这两个alpha值设置一个常数项b</span></div><div class="line">        b1 = b - Ei - labelMat[i] * (alphas[i] - alphaIold) * dataMatrix[i, :] * dataMatrix[i, :].T - labelMat[j] * (alphas[j] - alphaJold) * dataMatrix[i, :] * dataMatrix[j, :].T</div><div class="line">        b2 = b - Ej - labelMat[i] * (alphas[i] - alphaIold) * dataMatrix[i, :] * dataMatrix[j, :].T - labelMat[j] * (alphas[j] - alphaJold) * dataMatrix[j, :] * dataMatrix[j, :].T</div><div class="line"></div><div class="line">        <span class="keyword">if</span> ( <span class="number">0</span> &lt; alphas[i] ) <span class="keyword">and</span> ( C &gt; alphas[i] ) : b = b1</div><div class="line">        <span class="keyword">elif</span> ( <span class="number">0</span> &lt; alphas[j] ) <span class="keyword">and</span> ( C &gt; alphas[j] ) : b = b2</div><div class="line">        <span class="keyword">else</span> : b = ( b1 + b2 ) / <span class="number">2.0</span></div><div class="line"></div><div class="line">        <span class="comment"># 成功的改变了alpha，计数</span></div><div class="line">        alphaPairsChanged += <span class="number">1</span></div><div class="line">        <span class="keyword">print</span> <span class="string">"iter: %d i: %d, pairs changed %d"</span> % (iter, i, alphaPairsChanged)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (alphaPairsChanged == <span class="number">0</span>) : iter += <span class="number">1</span></div><div class="line">    <span class="keyword">else</span> : iter = <span class="number">0</span></div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">"iteration number: %d"</span> % iter</div><div class="line">  <span class="keyword">return</span> b, alphas</div></pre></td></tr></table></figure>
<p>这个函数比较大，可能是学习过程中最大的一个函数了，希望大家细细的看一下代码的注释。</p>
<p><em>函数的解析我还是等一个头脑清醒的时候弄吧，现在已经12点10分了，稍有点晕乎，去搞搞业务代码</em> </p>
<blockquote>
<p>由于SMO算法的随机性，所以运行后得到的结果可能每次都不同。</p>
</blockquote>
<p><code>alphas[alphas &gt; 0]</code>命令是数组过滤的一个实例，只对Numpy类型有用。</p>
<p>为了得到支持向量的个数，输入:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">shape(alphas[alphas &gt; <span class="number">0</span>])</div></pre></td></tr></table></figure>
<h6 id="利用完整-Platt-SMO-算法加速优化"><a href="#利用完整-Platt-SMO-算法加速优化" class="headerlink" title="利用完整 Platt SMO 算法加速优化"></a>利用完整 Platt SMO 算法加速优化</h6><p>在几百个点组成的小规模数据集上，简化版 SMO 算法的运行是没有什么问题的，但是在更大的数据集上的运行速度就会变慢，下面我们讨论完整的SMO算法。这两个版本中，实现alpha的更改和代数运算的优化环节是相同的。在优化的过程中，唯一不同的是选择alpha的方式。完整的SMO算法应用了一些能够提速的启发方法。<br><code>Platt SMO</code> 算法是通过一个外循环来选择第一个alpha值的，并且选择过程会在两种方式之间进行交替：</p>
<ul>
<li>在所有数据集上进行单遍扫描</li>
<li>在非边界alpha中实现单遍扫描 （不等于边界0或者C的alpha值）</li>
</ul>
<p>对整个数据的扫描非常容易，而实现非边界alpha的扫描时，首先需要建立这些alpha值的列表，然后在对这个表进行遍历，同时该步骤会跳过那些已知的不会改变的alpha值。</p>
<p>在选择第一个alpha值之后，算法会通过一个内循环来选择第二个alpha值。在优化过程中，会通过 <code>最大化步长</code> 的方式来获得第二个alpha值。在简化版SMO算法中，我们会在选择 j 之后计算错误率 Ej 。但是在这里，我们会建立一个全局的缓存用于保存误差值，并从中选择使得步长或者说 <code>Ei-Ej</code> 最大的alpha值。并且我们在其中加入了 <code>核函数</code>，核函数作为一种工具，将数据转换成易于分类器理解的形式。下边加入的是一种称为 <code>径向基函数</code> 的最流行的核函数。那么究竟什么是核函数呢？</p>
<p><img src="../imgs/ml-svm-12.png" alt=""></p>
<p>如上图所示，数据点处于一个圆中，人类的大脑可以看出来，但是对于分类器而言，它只能识别分类器的结果是大于 0 还是小于 0 ，如果只在x、y轴画线进行分类的话，我们并不会得到理想的结果。所以我们将数据从一个特征空间转换到另一个特征空间，在新的空间下，我们可以很容易的利用已有的工具对数据进行处理，数学家们喜欢将这个过程称之为 <code>从一个特征空间到另一个特征空间的映射</code>。在通常情况下，这种映射会将低维特征空间映射到高维空间。这个过程是通过核函数来实现的。可以把核函数想为一个 <code>包装器</code> 或者是 <code>接口</code> ，它能把数据从某个很难处理的形式转换成为另一个较容易处理的形式。</p>
<blockquote>
<p>在SVM优化中一个特别好的地方就是，所有的运算都可以写成 <code>内积</code> （也称 <code>点积</code>）的形式。向量的内积指的是两个向量相乘，之后得到单个标量或者数值。我们可以把内积运算替换成核函数，而不必做简化处理。将内积替换成核函数的方式被称为 <code>核技巧</code> 或者 <code>核变电</code>。</p>
</blockquote>
<h6 id="径向基核函数"><a href="#径向基核函数" class="headerlink" title="径向基核函数"></a>径向基核函数</h6><p>这是一个在SVM中常用的一个核函数，径向基函数是一个采用向量作为自变量的函数，能够基于向量距离运算输出一个标量。接下来，我们将会使用到径向基函数的高斯版本，其具体公式为：</p>
<p><img src="../imgs/ml-svm-13.png" alt=""></p>
<p>其中，σ 是用户定义的用于确定 <code>到达率</code> 或者说函数值跌落到 0 的速度参数。接下来我们写出完整的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">optStruct</span>:</span></div><div class="line"></div><div class="line">    <span class="comment"># 用于存放重要值的数据结构，方便传递，作为一个数据结构来使用</span></div><div class="line">    <span class="comment"># kTup包含核函数信息的元组</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataMatIn, classLabels, C, toler, kTup)</span>:</span></div><div class="line">        self.X = dataMatIn</div><div class="line">        self.labelMat = classLabels</div><div class="line">        self.C = C</div><div class="line">        self.tol = toler</div><div class="line">        self.m = shape(dataMatIn)[<span class="number">0</span>]</div><div class="line">        self.alphas = mat(zeros((self.m, <span class="number">1</span>)))</div><div class="line">        self.b = <span class="number">0</span></div><div class="line">        self.eCache = mat(zeros((self.m, <span class="number">2</span>)))</div><div class="line">        self.K = mat(zeros((self.m, self.m)))</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.m):</div><div class="line">            self.K[:, i] = kernelTrans(self.X, self.X[i, :], kTup) <span class="comment"># 使用核函数进行维度变换</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcEk</span><span class="params">(oS, k)</span>:</span></div><div class="line">    fXk = float(multiply(oS.alphas, oS.labelMat).T * oS.K[:, k] + oS.b)</div><div class="line">    Ek = fXk - float(oS.labelMat[k])</div><div class="line">    <span class="keyword">return</span> Ek</div><div class="line"></div><div class="line"><span class="comment"># 用于选择第二个alpha或者说内循环的alpha值</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJ</span><span class="params">(i, oS, Ei)</span>:</span></div><div class="line">    maxK = <span class="number">-1</span></div><div class="line">    maxDeltaE = <span class="number">0</span></div><div class="line">    Ej = <span class="number">0</span></div><div class="line">    </div><div class="line">    <span class="comment"># 选择合适的第二个alpha值以保证在每次优化中采用最大步长</span></div><div class="line">    oS.eCache[i] = [<span class="number">1</span>, Ei]</div><div class="line">    validEcacheList = nonzero(oS.eCache[:, <span class="number">0</span>].A)[<span class="number">0</span>]</div><div class="line">    <span class="keyword">if</span> (len(validEcacheList)) &gt; <span class="number">1</span>:</div><div class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> validEcacheList:  </div><div class="line">            <span class="keyword">if</span> k == i:</div><div class="line">                <span class="keyword">continue</span>  <span class="comment"># 不需要计算i了，浪费时间</span></div><div class="line">            Ek = calcEk(oS, k)</div><div class="line">            deltaE = abs(Ei - Ek)</div><div class="line">            <span class="keyword">if</span> (deltaE &gt; maxDeltaE):</div><div class="line">                maxK = k</div><div class="line">                maxDeltaE = deltaE</div><div class="line">                Ej = Ek</div><div class="line">        <span class="keyword">return</span> maxK, Ej</div><div class="line">    <span class="keyword">else</span>: <span class="comment"># 第一次循环我们会随机选择一个alpha值</span></div><div class="line">        j = selectJrand(i, oS.m)</div><div class="line">        Ej = calcEk(oS, j)</div><div class="line">    <span class="keyword">return</span> j, Ej</div><div class="line"></div><div class="line"><span class="comment"># 计算误差值并存放到缓存当中</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateEk</span><span class="params">(oS, k)</span>:</span></div><div class="line">    Ek = calcEk(oS, k)</div><div class="line">    oS.eCache[k] = [<span class="number">1</span>, Ek]</div><div class="line"></div><div class="line"><span class="comment"># 完整的优化过程</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">innerL</span><span class="params">(i, oS)</span>:</span></div><div class="line">    Ei = calcEk(oS, i)</div><div class="line">    <span class="keyword">if</span> ((oS.labelMat[i] * Ei &lt; -oS.tol) <span class="keyword">and</span> (oS.alphas[i] &lt; oS.C)) <span class="keyword">or</span> ((oS.labelMat[i] * Ei &gt; oS.tol) <span class="keyword">and</span> (oS.alphas[i] &gt; <span class="number">0</span>)):</div><div class="line">        j, Ej = selectJ(i, oS, Ei)  <span class="comment"># 第二个alpha选择器中的启发式方法</span></div><div class="line">        alphaIold = oS.alphas[i].copy()</div><div class="line">        alphaJold = oS.alphas[j].copy()</div><div class="line">        <span class="keyword">if</span> (oS.labelMat[i] != oS.labelMat[j]):</div><div class="line">            L = max(<span class="number">0</span>, oS.alphas[j] - oS.alphas[i])</div><div class="line">            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            L = max(<span class="number">0</span>, oS.alphas[j] + oS.alphas[i] - oS.C)</div><div class="line">            H = min(oS.C, oS.alphas[j] + oS.alphas[i])</div><div class="line">        <span class="keyword">if</span> L == H:</div><div class="line">            <span class="keyword">print</span> <span class="string">"L==H"</span></div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        eta = <span class="number">2.0</span> * oS.K[i, j] - oS.K[i, i] - oS.K[j, j]</div><div class="line">        <span class="keyword">if</span> eta &gt;= <span class="number">0</span>:</div><div class="line">            <span class="keyword">print</span> <span class="string">"eta&gt;=0"</span></div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej) / eta</div><div class="line">        oS.alphas[j] = clipAlpha(oS.alphas[j], H, L)</div><div class="line">        updateEk(oS, j)  <span class="comment"># 更新误差缓存</span></div><div class="line">        <span class="keyword">if</span> (abs(oS.alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>):</div><div class="line">            <span class="keyword">print</span> <span class="string">"j not moving enough"</span></div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        oS.alphas[i] += oS.labelMat[j] * oS.labelMat[i] * \</div><div class="line">            (alphaJold - oS.alphas[j])</div><div class="line">        updateEk(oS, i) <span class="comment"># 更新误差缓存</span></div><div class="line">        b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[</div><div class="line">            i, i] - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.K[i, j]</div><div class="line">        b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[</div><div class="line">            i, j] - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.K[j, j]</div><div class="line">        <span class="keyword">if</span> (<span class="number">0</span> &lt; oS.alphas[i]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[i]):</div><div class="line">            oS.b = b1</div><div class="line">        <span class="keyword">elif</span> (<span class="number">0</span> &lt; oS.alphas[j]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[j]):</div><div class="line">            oS.b = b2</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            oS.b = (b1 + b2) / <span class="number">2.0</span></div><div class="line">        <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line"></div><div class="line"><span class="comment"># 完整的 Platt SMO 优化算法</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoP</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter, kTup=<span class="params">(<span class="string">'lin'</span>, <span class="number">0</span>)</span>)</span>:</span>  </div><div class="line">    oS = optStruct(mat(dataMatIn), mat(</div><div class="line">        classLabels).transpose(), C, toler, kTup)</div><div class="line">    iter = <span class="number">0</span></div><div class="line">    entireSet = <span class="keyword">True</span></div><div class="line">    alphaPairsChanged = <span class="number">0</span></div><div class="line">    <span class="keyword">while</span> (iter &lt; maxIter) <span class="keyword">and</span> ((alphaPairsChanged &gt; <span class="number">0</span>) <span class="keyword">or</span> (entireSet)):</div><div class="line">        alphaPairsChanged = <span class="number">0</span></div><div class="line">        <span class="keyword">if</span> entireSet:  <span class="comment"># 遍历所有的值</span></div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(oS.m):</div><div class="line">                alphaPairsChanged += innerL(i, oS)</div><div class="line">                <span class="keyword">print</span> <span class="string">"fullSet, iter: %d i:%d, pairs changed %d"</span> % (iter, i, alphaPairsChanged)</div><div class="line">            iter += <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:  <span class="comment"># go over non-bound (railed) alphas</span></div><div class="line">            nonBoundIs = nonzero((oS.alphas.A &gt; <span class="number">0</span>) * (oS.alphas.A &lt; C))[<span class="number">0</span>]</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> nonBoundIs:</div><div class="line">                alphaPairsChanged += innerL(i, oS)</div><div class="line">                <span class="keyword">print</span> <span class="string">"non-bound, iter: %d i:%d, pairs changed %d"</span> % (iter, i, alphaPairsChanged)</div><div class="line">            iter += <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> entireSet:</div><div class="line">            entireSet = <span class="keyword">False</span>  <span class="comment"># toggle entire set loop</span></div><div class="line">        <span class="keyword">elif</span> (alphaPairsChanged == <span class="number">0</span>):</div><div class="line">            entireSet = <span class="keyword">True</span></div><div class="line">        <span class="keyword">print</span> <span class="string">"iteration number: %d"</span> % iter</div><div class="line">    <span class="keyword">return</span> oS.b, oS.alphas</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcWs</span><span class="params">(alphas, dataArr, classLabels)</span>:</span></div><div class="line">    X = mat(dataArr)</div><div class="line">    labelMat = mat(classLabels).transpose()</div><div class="line">    m, n = shape(X)</div><div class="line">    w = zeros((n, <span class="number">1</span>))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        w += multiply(alphas[i] * labelMat[i], X[i, :].T)</div><div class="line">    <span class="keyword">return</span> w</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kernelTrans</span><span class="params">(X, A, kTup)</span>:</span> <span class="comment">#calc the kernel or transform data to a higher dimensional space</span></div><div class="line">    m,n = shape(X)</div><div class="line">    K = mat(zeros((m,<span class="number">1</span>)))</div><div class="line">    <span class="keyword">if</span> kTup[<span class="number">0</span>]==<span class="string">'lin'</span>: K = X * A.T   <span class="comment">#linear kernel</span></div><div class="line">    <span class="keyword">elif</span> kTup[<span class="number">0</span>]==<span class="string">'rbf'</span>:</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</div><div class="line">            deltaRow = X[j,:] - A</div><div class="line">            K[j] = deltaRow*deltaRow.T</div><div class="line">        K = exp(K/(<span class="number">-1</span>*kTup[<span class="number">1</span>]**<span class="number">2</span>)) <span class="comment">#divide in NumPy is element-wise not matrix like Matlab</span></div><div class="line">    <span class="keyword">else</span>: <span class="keyword">raise</span> NameError(<span class="string">'Houston We Have a Problem -- \</span></div><div class="line">    That Kernel is not recognized')</div><div class="line">    <span class="keyword">return</span> K</div></pre></td></tr></table></figure>
<p>接下来我们编写一个测试函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testRbf</span><span class="params">(k1=<span class="number">0.1</span>)</span>:</span></div><div class="line">    dataArr,labelArr = loadDataSet(<span class="string">'testSetRBF.txt'</span>)</div><div class="line">    b,alphas = smoP(dataArr, labelArr, <span class="number">200</span>, <span class="number">0.0001</span>, <span class="number">10000</span>, (<span class="string">'rbf'</span>, k1)) <span class="comment">#C=200 important</span></div><div class="line">    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()</div><div class="line">    svInd=nonzero(alphas.A&gt;<span class="number">0</span>)[<span class="number">0</span>]</div><div class="line">    sVs=datMat[svInd] <span class="comment">#get matrix of only support vectors</span></div><div class="line">    labelSV = labelMat[svInd];</div><div class="line">    <span class="keyword">print</span> <span class="string">"there are %d Support Vectors"</span> % shape(sVs)[<span class="number">0</span>]</div><div class="line">    m,n = shape(datMat)</div><div class="line">    errorCount = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        kernelEval = kernelTrans(sVs,datMat[i,:],(<span class="string">'rbf'</span>, k1))</div><div class="line">        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b</div><div class="line">        <span class="keyword">if</span> sign(predict)!=sign(labelArr[i]): errorCount += <span class="number">1</span></div><div class="line">    <span class="keyword">print</span> <span class="string">"the training error rate is: %f"</span> % (float(errorCount)/m)</div><div class="line">    dataArr,labelArr = loadDataSet(<span class="string">'testSetRBF2.txt'</span>)</div><div class="line">    errorCount = <span class="number">0</span></div><div class="line">    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()</div><div class="line">    m,n = shape(datMat)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        kernelEval = kernelTrans(sVs,datMat[i,:],(<span class="string">'rbf'</span>, k1))</div><div class="line">        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b</div><div class="line">        <span class="keyword">if</span> sign(predict)!=sign(labelArr[i]): errorCount += <span class="number">1</span>    </div><div class="line">    <span class="keyword">print</span> <span class="string">"the test error rate is: %f"</span> % (float(errorCount)/m)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>reload(svmMLiA)</div><div class="line">&lt;module <span class="string">'svmMLiA'</span> <span class="keyword">from</span> <span class="string">'svmMLiA.pyc'</span>&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>svmMLiA.testRbf()</div></pre></td></tr></table></figure>
<p>随便更改测试函数中k的值，发现错误率不同，这个值与数据相关。</p>
<h6 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h6><p>支持向量机是一种分类器，是一种决策机，这是一个相当流行的算法。核方法不仅在SVM中适用，还可以用于其他算法，上边使用的径向基函数是一个常用的度量两个向量距离的核函数。支持向量机是一个二类分类器，当用其解决多类问题时，则需要额外的方法对其进行扩展。SVM的效果也对优化参数和所用核函数中的参数敏感。</p>

    
    
    <footer class="meta">
      
      
  <div class="tags">
<a href="/ml/tags/机器学习/">机器学习</a></div>

      
    </footer>
    
  </div>
  
</article></div>
  <footer id="footer" class="inner"><div class="social alignright">
  
    <a class="facebook" href="http://www.facebook.com/Dylanccccc" title="Facebook">Facebook</a>
  
  
  
    <a class="twitter" href="http://twitter.com/Dylanccccc" title="Twitter">Twitter</a>
  
  
    <a class="github" href="https://github.com/WildDylan" title="GitHub">GitHub</a>
  
  <a class="rss" href="/atom.xml" title="RSS">RSS</a>
</div>
<p>
  
  &copy; 2017 dylan
  
</p>
<div class="clearfix"></div></footer>
  <script src="/ml/js/jquery.imagesloaded.min.js"></script>
<script src="/ml/js/gallery.js"></script>




<link rel="stylesheet" href="/ml/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/ml/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<div id="phasebeam">
  <canvas></canvas>
  <canvas></canvas>
  <canvas></canvas>
</div>
<script src="/ml/js/phasebeam.js"></script>
</body>
</html>