<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习（决策树） | Machine-Learning</title>
  <meta name="author" content="dylan">

  
  <meta name="description" content="A place of Machine-Learning">
  
  

  <link rel="alternate" href="/atom.xml" title="Machine-Learning" type="application/atom+xml">
  <link rel="stylesheet" href="/ml/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8/jquery.min.js"></script>
  
</head>

<body>
  <header id="header" class="inner"><nav>
  <ul>
    
      <li><a href="">Machine-Learning</a></li>
    
  </ul>
</nav></header>
  <div id="content" class="inner"><article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <header>
    
  
    <h1 class="title">机器学习（决策树）</h1>
  

    <time datetime="2017-01-16T13:48:50.000Z">
  <span class="day">16</span><span class="month">Jan</span>
</time>
  </header>
  <div class="entry-content">
    
      <h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p>===</p>
<p>决策树简介</p>
<p>你是否玩过二十个问题的游戏，游戏的规则很简单：参与游戏的一方在脑海中想象某个事物，其他参与者者向他提问题，只允许提20个问题，问题的答案也只能用对或错回答。问问题的人通过推断分解，逐步缩小待猜测事物的范围。<br><code>决策树</code>的工作原理与20个问题类似，用户输入一系列的数据，然后给出游戏的答案。我们经常使用决策树处理分类问题，近来的调查表明，决策树也是最经常使用的数据挖掘算法。它之所以如此流行，一个很重要的原因就是不需要了解机器学习的知识，就能搞明白决策树是如何工作的。</p>
<a id="more"></a>
<p><img src="http://ocef2grmj.bkt.clouddn.com/ml-tree_1.png" alt=""></p>
<p>上边所示的图，就可以被称为是决策树，长方形代表<code>判断模块</code>，椭圆形代表<code>终止模块</code>，表示已经得出结论，可以终止运行。从判断模块引出的左右箭头被称为<code>分支</code>，它可以到达另一个判断模块或者终止模块。上图构造了一个假象的邮件分类系统，首先检测了邮箱的地址，接下来检测是否包含某一单词来决定是否为垃圾邮件。<br>上篇文章我们所学习的<code>k-近邻算法</code>可以完成很多分类任务，但是它最大的缺点就是无法给出数据的内在含义，决策树的主要优势在于数据形式非常容易理解。所以我们说，<code>决策树</code>的一个重要的任务是为了理解数据中所蕴含的知识信息，因此，决策树可以使用不熟悉的数据集合，并从中提取出一系列规则，这些机器根据数据集创建规则的过程，就是机器学习的过程。</p>
<blockquote>
<p>决策树给出的结果往往可以匹敌在当前领域具有几十年工作经验的人类专家。</p>
</blockquote>
<h4 id="决策树的构造"><a href="#决策树的构造" class="headerlink" title="决策树的构造"></a>决策树的构造</h4><p>在构造决策树之前，我们首先来看一下决策树的优缺点：</p>
<blockquote>
<p>优点：计算复杂度不高，输出结果容易理解，对中间值的缺失不敏感，可以处理不相关特征数据<br>缺点：可能会产生<code>过度匹配问题</code><br>适用数据类型：数值型、标称型</p>
</blockquote>
<ul>
<li>使用<code>信息论</code>划分数据集</li>
</ul>
<p>在构造决策树时，我们需要解决的第一个问题就是，哪个特征对于我们划分数据分类起决定性作用，在学习<code>k-近邻算法</code>的时候，我们在对社交网站进行升级时，对关键特征的选择是通过图中所分布的点来决定，这次我们通过<code>信息论</code>来计算和评估每个特征对分类的影响。<br>那么，如何划分数据集呢？我们约定，如果某个分支下的数据属于同一类型，则当前无需阅读的垃圾邮件已经正确的划分数据分类，无需进一步对数据集进行分割，如果数据自己内的数据不属于同一类型，则需要重复划分数据自己的过程，直到所有具有相同类型的数据均在一个数据子集内。<br>一些决策树算法采用二分法划分数据，但是我们使用<code>信息论</code>作为划分数据子集的工具。首先我们来了解一下什么是<code>信息增益</code>：</p>
<h6 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h6><p>划分数据子集的大原则是：将无序的数据变得更加有序。有很多方法可以用于划分数据子集，每种方法各有优缺点。组织杂乱无章数据的一种方法就是使用信息论度量信息，信息论是量化处理信息的分支科学。我们可以在划分数据之前或者之后使用信息论度量信息的内容。<br>在划分数据集之前之后信息发生的变化称为<code>信息增益</code>，知道如何计算信息增益，我们就可以计算每个特征值划分数据获得的信息增益，获得信息增益最高的特征就是最好的选择。那么，如何计算信息增益呢？集合信息的度量方式称为<code>香农熵</code>，或者简称为<code>熵</code>。</p>
<ul>
<li>熵，定义为信息的期望值，如果待分类的事务可能划分在多个分类之中，则符号X<sup>i</sup>的信息定义为：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">l(x&lt;sup&gt;i&lt;/sup&gt;) = -log&lt;sup&gt;2&lt;/sup&gt;p(x&lt;sup&gt;i&lt;/sup&gt;)</div></pre></td></tr></table></figure>
<p>其中，p(x<sup>i</sup>)是选择该分类的概率。为了计算熵，我们需要计算所有类别所有可能值包含的信息期望值，通过下面的公事得到：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">H = -求和（n, i=1） p(x&lt;sup&gt;i&lt;/sup&gt;)log&lt;sup&gt;2&lt;/sup&gt;p(x&lt;sup&gt;i&lt;/sup&gt;)</div></pre></td></tr></table></figure>
<p>其中，n是分类的数目。</p>
<blockquote>
<p>注，由于github的markdown暂不支持数学公事，所以一些数学符号我暂时用文字或者math中的方法名称代替，比如说 sqrt 等等</p>
</blockquote>
<p>下面我们使用代码来实现计算信息熵，创建名为<code>trees.py</code>的文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(dataSet)</span> :</span></div><div class="line">    numEntries = len(dataSet) <span class="comment"># 获得数据集中实例的总数</span></div><div class="line">    labelCounts = &#123;&#125; <span class="comment"># 创建数据字典，它的键值是最后一列的数值，每个键值都记录了当前类别出现的次数</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet :</div><div class="line">        currentLabel = featVec[<span class="number">-1</span>]</div><div class="line"></div><div class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys() :</div><div class="line">            labelCounts[currentLabel] = <span class="number">0</span></div><div class="line">        </div><div class="line">        labelCounts[currentLabel] += <span class="number">1</span></div><div class="line"></div><div class="line">    shannonEnt = <span class="number">0.0</span></div><div class="line">    <span class="comment"># 使用类别标签发生的频率，计算类别出现的概率，将用这个值计算熵</span></div><div class="line">    <span class="keyword">for</span> Key <span class="keyword">in</span> labelCounts :</div><div class="line">        prob = float(labelCounts[Key]) / numEntries</div><div class="line">        shannonEnt -= prob * log(prob, <span class="number">2</span>)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> shannonEnt</div></pre></td></tr></table></figure>
<p>接下来我们创建一个简单的数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span> :</span></div><div class="line">    dataSet = [</div><div class="line">      [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</div><div class="line">      [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</div><div class="line">      [<span class="number">1</span>, <span class="number">0</span>, <span class="string">'no'</span>],</div><div class="line">      [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>],</div><div class="line">      [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>]</div><div class="line">    ]</div><div class="line"></div><div class="line">    labels = [<span class="string">'no surfacing'</span>, <span class="string">'flippers'</span>]</div><div class="line">    <span class="keyword">return</span> dataSet, labels</div></pre></td></tr></table></figure>
<p>然后我们来测试一下上述内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>reload(trees)</div><div class="line">&lt;module <span class="string">'trees'</span> <span class="keyword">from</span> <span class="string">'trees.py'</span>&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myData, labels = trees.createDataSet()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>trees.calcShannonEnt(myData)</div><div class="line"><span class="number">0.9709505944546686</span></div></pre></td></tr></table></figure>
<p><strong>熵越高，则混合的数据也越多</strong>，我们可以在集合中添加更多的分类，观察熵是如何变化的，这里我们新增一个名为<code>hello</code>的分类并测试</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>myData[<span class="number">0</span>][<span class="number">-1</span>] = <span class="string">'hello'</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myData</div><div class="line">[[<span class="number">1</span>, <span class="number">1</span>, <span class="string">'hello'</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>], [<span class="number">1</span>, <span class="number">0</span>, <span class="string">'no'</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>trees.calcShannonEnt(myData)</div><div class="line"><span class="number">1.3709505944546687</span></div><div class="line"></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myData[<span class="number">2</span>][<span class="number">-1</span>] = <span class="string">'machine'</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myData</div><div class="line">[[<span class="number">1</span>, <span class="number">1</span>, <span class="string">'hello'</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>], [<span class="number">1</span>, <span class="number">0</span>, <span class="string">'machine'</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>trees.calcShannonEnt(myData)</div><div class="line"><span class="number">1.9219280948873623</span></div></pre></td></tr></table></figure>
<p>我们看到，分类越多，熵值越高。得到熵之后，我们就可以按照获取最大信息增益的方法划分数据集。下面我们来学习如何划分数据集，并创建决策树。</p>
<h6 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a>划分数据集</h6><p>我们将对每个特征划分数据集的结果计算一次信息熵，然后判断按照哪个特征划分数据集是最好的划分方式。我们来按照给定的特征划分数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"> <span class="comment"># 输入的参数分别为，待划分的数据集，划分数据集的特征，需要返回的特征的值</span></div><div class="line"> <span class="comment"># 注：python语言方法中传递的是列表的引用，为了不改变源数据，所以我们用一个新的变量来存储返回结果</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span><span class="params">(dataSet, axis, value)</span> :</span></div><div class="line">    retDataSet = [] <span class="comment"># 列表中的各个元素也是列表，我们要遍历数据集中的每个元素，一旦发现符合要求的值，则将其添加到新创建的列表中</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet :</div><div class="line">        <span class="keyword">if</span> featVec[axis] == value : <span class="comment"># 将符合特征的数据抽取出来</span></div><div class="line">            reducedFeatVec = featVec[: axis]</div><div class="line">            reducedFeatVec.extend(featVec[axis+<span class="number">1</span> :])</div><div class="line">            retDataSet.append(reducedFeatVec)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> retDataSet</div></pre></td></tr></table></figure>
<blockquote>
<p>注：代码中用到的<code>append</code>与<code>extend</code>方法略有不同，extent是将当前列表的元素添加到源列表中，append意为将该列表作为元素添加至源列表中</p>
</blockquote>
<p>我们可以这样理解这段代码，当我们按照某个特征划分数据集时，就需要将所有符合要求的元素抽取出来。接下来，我们看一下代码的效果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>reload(trees)</div><div class="line">&lt;module <span class="string">'trees'</span> <span class="keyword">from</span> <span class="string">'trees.py'</span>&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myData, labels = trees.createDataSet()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>trees.splitDataSet(myData, <span class="number">0</span>, <span class="number">1</span>)</div><div class="line">[[<span class="number">1</span>, <span class="string">'yes'</span>], [<span class="number">1</span>, <span class="string">'yes'</span>], [<span class="number">0</span>, <span class="string">'no'</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>trees.splitDataSet(myData, <span class="number">0</span>, <span class="number">0</span>)</div><div class="line">[[<span class="number">1</span>, <span class="string">'no'</span>], [<span class="number">1</span>, <span class="string">'no'</span>]]</div></pre></td></tr></table></figure>
<p>我们看到，当特征为0的时候，我们希望返回特征值为1的对象，我们看一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>], [<span class="number">1</span>, <span class="number">0</span>, <span class="string">'no'</span>]</div></pre></td></tr></table></figure>
<p>这3个对象的第一个特征值均为1，所以程序没问题，大家也可以测试下其他特征。接下来我们遍历整个数据集，找到最好的特征划分方式，熵计算将会告诉我们如何划分数据集是最好的数据组织方式。</p>
<h6 id="选择最好的数据集划分方式"><a href="#选择最好的数据集划分方式" class="headerlink" title="选择最好的数据集划分方式"></a>选择最好的数据集划分方式</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit</span><span class="params">(dataSet)</span> :</span> </div><div class="line">    numFeatures = len(dataSet[<span class="number">0</span>]) - <span class="number">1</span> <span class="comment"># 判断有多少个特征属性</span></div><div class="line">    baseEntropy = calcShannonEnt(dataSet) <span class="comment"># 获得整个数据集的原始香农熵</span></div><div class="line">    bestInfoGain = <span class="number">0.0</span></div><div class="line">    bestFeature = <span class="number">-1</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures) :  <span class="comment"># 遍历数据集中所有的特征</span></div><div class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet] <span class="comment"># 使用[列表推倒](https://www.baidu.com/s?wd=python%20列表推倒&amp;rsv_spt=1&amp;rsv_iqid=0xea8c6dc30000af65&amp;issp=1&amp;f=8&amp;rsv_bp=0&amp;rsv_idx=2&amp;ie=utf-8&amp;tn=baiduhome_pg&amp;rsv_enter=1&amp;rsv_sug3=24&amp;rsv_sug1=20&amp;rsv_sug7=100&amp;rsv_sug2=0&amp;inputT=5475&amp;rsv_sug4=6400)来创建新的列表</span></div><div class="line">        uniqueVals = set(featList) <span class="comment"># 使用set将list去重</span></div><div class="line">        newEntropy = <span class="number">0.0</span></div><div class="line"></div><div class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals : <span class="comment"># 遍历当前特征中所有唯一的属性值，对每个唯一的属性值划分一次数据集</span></div><div class="line">            subDataSet = splitDataSet(dataSet, i, value) </div><div class="line">            prob = len(subDataSet) / float(len(dataSet))</div><div class="line">            newEntropy += prob * calcShannonEnt(subDataSet) <span class="comment"># 计算熵，求和</span></div><div class="line"></div><div class="line">        infoGain = baseEntropy - newEntropy</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (infoGain &gt; bestInfoGain) : <span class="comment"># 比较所有特征的熵（信息增益），返回用于划分的最好特征的索引值</span></div><div class="line">            bestInfoGain = infoGain</div><div class="line">            bestFeature = i</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> bestFeature</div></pre></td></tr></table></figure>
<p>该函数实现了选取特征，划分数据集，计算出最好的划分数据集的特征的功能。调用该函数需要满足一定的要求：1. 数据必须是一种由列表元素组成的列表，而且所有列表元素的长度都相同。 2. 数据的最后一列或者每个实例的最后一个元素是当前实例的类别标签。3. 我们无需先定list中的数据类型。</p>
<p>运行得出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>reload(trees)</div><div class="line">&lt;module <span class="string">'trees'</span> <span class="keyword">from</span> <span class="string">'trees.py'</span>&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myData, labels = trees.createDataSet()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>trees.chooseBestFeatureToSplit(myData)</div><div class="line"><span class="number">0</span></div></pre></td></tr></table></figure>
<h6 id="构建决策树"><a href="#构建决策树" class="headerlink" title="构建决策树"></a>构建决策树</h6><p>得到原始数据集，然后基于最好的属性值划分数据集，由于特征值可能多于2个，因此可能存在大于两个分支的数据集划分，第一次划分后，数据将被向下传递到树分支的下一个节点，在这个节点上，我们可以再次划分数据。因此，我们采用递归的方式处理数据集。递归结束的条件是：程序遍历完所有划分数据集的属性，或者每个分支下的所有实例都具有相同的分类，如果实例都具有相同的分类，则得到一个叶子节点或者终止块，任何到达叶子节点的数据必然属于叶子节点的分类。如果数据集已经处理了所有属性，但是类标签依然不是唯一的，此时我们需要决定如何定义该叶子节点，在这种情况下，我们通常会采用多数表决的方式决定该叶子节点的分类。</p>
<p>首先在trees.py中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> operator</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(classList)</span> :</span> <span class="comment"># 分类名称的列表</span></div><div class="line">    classCount = &#123;&#125;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList :</div><div class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys() : classCount[vote] = <span class="number">0</span></div><div class="line"></div><div class="line">        classCount[vote] += <span class="number">1</span> <span class="comment"># 存储每个列表标签出现的频率</span></div><div class="line"></div><div class="line">    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>) <span class="comment"># 排序并返回出现次数最多的分类名称</span></div><div class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</div></pre></td></tr></table></figure>
<p>接下来我们来创建树，大家细看注释：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 输入数据集、标签列表</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, labels)</span> :</span></div><div class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet] <span class="comment"># 包含数据集所有的类标签</span></div><div class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList) :  </div><div class="line">      <span class="keyword">return</span> classList[<span class="number">0</span>] <span class="comment"># 所有的类标签完全相同，则直接返回该类标签</span></div><div class="line">    </div><div class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span> :</div><div class="line">      <span class="keyword">return</span> majorityCnt(classList) <span class="comment"># 使用完了所有特征，仍然不能将数据集划分为仅包含唯一类别的分组，由于第二个终止条件无法简单的返回唯一的类标签，我们使用出现次数最多的累标签作为返回值</span></div><div class="line"></div><div class="line">    <span class="comment"># 开始创建树</span></div><div class="line">    bestFeat = chooseBestFeatureToSplit(dataSet) <span class="comment"># 存放最优特征列</span></div><div class="line">    bestFeatLabel = labels[bestFeat] </div><div class="line"></div><div class="line">    myTree = &#123;bestFeatLabel:&#123;&#125;&#125; <span class="comment"># 使用字典存储树的信息</span></div><div class="line">    <span class="keyword">del</span>(labels[bestFeat])</div><div class="line"></div><div class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line">    uniqueVals = set(featValues) <span class="comment"># 得到列表包含的所有属性值</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals : <span class="comment"># 遍历当前选择特征包含的所有属性值</span></div><div class="line">        subLabels = labels[:] <span class="comment"># 复制类标签</span></div><div class="line">        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels) <span class="comment"># 每个数据集调用上，递归调用函数创建树</span></div><div class="line"></div><div class="line">    <span class="keyword">return</span> myTree</div></pre></td></tr></table></figure>
<p>运行上述代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>reload(trees)</div><div class="line">&lt;module <span class="string">'trees'</span> <span class="keyword">from</span> <span class="string">'trees.py'</span>&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myData, labels = trees.createDataSet()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myTree = trees.createTree(myData, labels)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myTree</div><div class="line">&#123;<span class="string">'no surfacing'</span>: &#123;<span class="number">0</span>: <span class="string">'no'</span>, <span class="number">1</span>: &#123;<span class="string">'flippers'</span>: &#123;<span class="number">0</span>: <span class="string">'no'</span>, <span class="number">1</span>: <span class="string">'yes'</span>&#125;&#125;&#125;&#125;</div></pre></td></tr></table></figure>
<ul>
<li>扩展：如何使用MapPlotlib绘制树</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> treePlotter</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myTree = treePlotter.retrieveTree(<span class="number">0</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myTree</div><div class="line">&#123;<span class="string">'no surfacing'</span>: &#123;<span class="number">0</span>: <span class="string">'no'</span>, <span class="number">1</span>: &#123;<span class="string">'flippers'</span>: &#123;<span class="number">0</span>: <span class="string">'no'</span>, <span class="number">1</span>: <span class="string">'yes'</span>&#125;&#125;&#125;&#125;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>treePlotter.createPlot(myTree)</div></pre></td></tr></table></figure>
<p>大家阅读下相关代码</p>
<h6 id="测试算法"><a href="#测试算法" class="headerlink" title="测试算法"></a>测试算法</h6><p>我们继续在trees.py中添加方法，一个使用决策树的分类方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(inputTree, featLabels, testVec)</span> :</span></div><div class="line">    firstStr = inputTree.keys() [<span class="number">0</span>]</div><div class="line">    secondDict = inputTree[firstStr]</div><div class="line"></div><div class="line">    featIndex = featLabels.index(firstStr)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys() :</div><div class="line">      <span class="keyword">if</span> testVec[featIndex] == key :</div><div class="line">        <span class="keyword">if</span> type(secondDict[key]).__name__ == <span class="string">'dict'</span> :</div><div class="line">          classLabel = classify(secondDict[key], featLabels, testVec)</div><div class="line">        <span class="keyword">else</span>: classLabel = secondDict[key]</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> classLabel</div></pre></td></tr></table></figure>
<p>进行测试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>reload(trees)</div><div class="line">&lt;module <span class="string">'trees'</span> <span class="keyword">from</span> <span class="string">'trees.py'</span>&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myData, labels = trees.createDataSet()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>labels</div><div class="line">[<span class="string">'no surfacing'</span>, <span class="string">'flippers'</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myTree = treePlotter.retrieveTree(<span class="number">0</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>myTree</div><div class="line">&#123;<span class="string">'no surfacing'</span>: &#123;<span class="number">0</span>: <span class="string">'no'</span>, <span class="number">1</span>: &#123;<span class="string">'flippers'</span>: &#123;<span class="number">0</span>: <span class="string">'no'</span>, <span class="number">1</span>: <span class="string">'yes'</span>&#125;&#125;&#125;&#125;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>trees.classify(myTree, labels, [<span class="number">1</span>, <span class="number">0</span>])</div><div class="line"><span class="string">'no'</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>trees.classify(myTree, labels, [<span class="number">1</span>, <span class="number">1</span>])</div><div class="line"><span class="string">'yes'</span></div></pre></td></tr></table></figure>
<p>上面代码中，myTree我们是从<code>treePlotter</code>中获取的已经手工将之前创建号的树写死到代码里的，但是实际情况中，我们需要把树保存到本地供使用，所以我们来看下如何保存树，也就是决策树的存储。</p>
<h6 id="决策树的存储"><a href="#决策树的存储" class="headerlink" title="决策树的存储"></a>决策树的存储</h6><p>我们依旧在trees.py中添加以下2个方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeTree</span><span class="params">(inputTree, filename)</span> :</span></div><div class="line">    <span class="keyword">import</span> pickle</div><div class="line"></div><div class="line">    fw = open(filename, <span class="string">'w'</span>)</div><div class="line">    pickle.dump(inputTree, fw)</div><div class="line">    fw.close</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">grabTree</span><span class="params">(filename)</span> :</span></div><div class="line">    <span class="keyword">import</span> pickle</div><div class="line">    </div><div class="line">    fr = open(filename)</div><div class="line">    <span class="keyword">return</span> pickle.load(fr)</div></pre></td></tr></table></figure>
<p>接下来，我们验证一下效果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>reload(trees)</div><div class="line">&lt;module <span class="string">'trees'</span> <span class="keyword">from</span> <span class="string">'trees.py'</span>&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>trees.storeTree(treePlotter.retrieveTree(<span class="number">0</span>), <span class="string">'sTree.txt'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>trees.grabTree(<span class="string">'sTree.txt'</span>)</div><div class="line">&#123;<span class="string">'no surfacing'</span>: &#123;<span class="number">0</span>: <span class="string">'no'</span>, <span class="number">1</span>: &#123;<span class="string">'flippers'</span>: &#123;<span class="number">0</span>: <span class="string">'no'</span>, <span class="number">1</span>: <span class="string">'yes'</span>&#125;&#125;&#125;&#125;</div><div class="line">&gt;&gt;&gt;</div></pre></td></tr></table></figure>
<h4 id="示例工程，使用决策树预测隐形眼睛类型"><a href="#示例工程，使用决策树预测隐形眼睛类型" class="headerlink" title="示例工程，使用决策树预测隐形眼睛类型"></a>示例工程，使用决策树预测隐形眼睛类型</h4><p>样本文件我存放到了跟代码以及的目录下，大家可以使用。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; fr = open('lenses.txt')</div><div class="line">&gt;&gt;&gt; lenses = [inst.strip().split('\t') for inst in fr.readlines()]</div><div class="line">&gt;&gt;&gt; lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']</div><div class="line">&gt;&gt;&gt; lensesTree = trees.createTree(lenses, lensesLabels)</div><div class="line">&gt;&gt;&gt; lensesTree</div><div class="line">&#123;'tearRate': &#123;'reduced': 'no lenses', 'normal': &#123;'astigmatic': &#123;'yes': &#123;'prescript': &#123;'hyper': &#123;'age': &#123;'pre': 'no lenses', 'presbyopic': 'no lenses', 'youn</div><div class="line">g': 'hard'&#125;&#125;, 'myope': 'hard'&#125;&#125;, 'no': &#123;'age': &#123;'pre': 'soft', 'presbyopic': &#123;'prescript': &#123;'hyper': 'soft', 'myope': 'no lenses'&#125;&#125;, 'young': 'soft'&#125;&#125;&#125;&#125;&#125;&#125;</div><div class="line">&gt;&gt;&gt; treePlotter.createPlot(lensesTree)</div></pre></td></tr></table></figure>
<p>并且我们得到了树图：</p>
<p><img src="http://ocef2grmj.bkt.clouddn.com/ml-tree_1.png" alt=""></p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>决策树分类器就像带有终止块的流程图，终止块表示分类结果，开始处理数据集时，我们首先测量数据的不一致性，也就是熵，然后寻找最优方案划分数据集，直到数据集中的所有数据属于同一分类。决策树分类器就像带有终止块的流程图，终止块表示分类结果，开始处理数据集时，我们首先测量数据的不一致性，也就是熵，然后寻找最优方案划分数据集，直到数据集中的所有数据属于同一分类。</p>

    
    
    <footer class="meta">
      
      
  <div class="tags">
<a href="/ml/tags/机器学习/">机器学习</a></div>

      
    </footer>
    
  </div>
  
</article></div>
  <footer id="footer" class="inner"><div class="social alignright">
  
    <a class="facebook" href="http://www.facebook.com/Dylanccccc" title="Facebook">Facebook</a>
  
  
  
    <a class="twitter" href="http://twitter.com/Dylanccccc" title="Twitter">Twitter</a>
  
  
    <a class="github" href="https://github.com/WildDylan" title="GitHub">GitHub</a>
  
  <a class="rss" href="/atom.xml" title="RSS">RSS</a>
</div>
<p>
  
  &copy; 2017 dylan
  
</p>
<div class="clearfix"></div></footer>
  <script src="/ml/js/jquery.imagesloaded.min.js"></script>
<script src="/ml/js/gallery.js"></script>




<link rel="stylesheet" href="/ml/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/ml/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<div id="phasebeam">
  <canvas></canvas>
  <canvas></canvas>
  <canvas></canvas>
</div>
<script src="/ml/js/phasebeam.js"></script>
</body>
</html>